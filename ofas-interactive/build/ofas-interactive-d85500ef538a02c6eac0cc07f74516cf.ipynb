{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ofas Interactive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "One way of interacting with a long running Spark application in Ofas is to use notebooks. We also offer two interfaces namely the new Spark Connect and JDBC through the HiveThriftServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Connect\n",
    "To start a Spark application with SparkConnect server, either run the mainClass SparkConnectServer or enable the SparkConnect plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Connect launch option 1\n",
    "```json\n",
    "\"mainClass\": \"org.apache.spark.connect.sql.service.SparkConnectServer\",\n",
    "\"deps\": {\n",
    "    \"packages\": [\"org.apache.spark:spark-connect_2.12:3.5.0\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Connect launch option 2\n",
    "```json\n",
    "\"sparkConf\": {\n",
    "    \"spark.plugins\": \"org.apache.spark.sql.connect.SparkConnectPlugin\"\n",
    "},\n",
    "\"deps\": {\n",
    "    \"packages\": [\"org.apache.spark:spark-connect_2.12:3.5.0\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the client side use the ocean-spark-connect (https://pypi.org/project/ocean-spark-connect) python library to interact with the Spark Connect session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ocean_spark_connect.ocean_spark_session import OceanSparkSession\n",
    "\n",
    "spark = OceanSparkSession.Builder().cluster_id(\"osc-cluster\").appid(\"appid\").profile(\"default\").getOrCreate()\n",
    "spark.sql(\"select random()\").show()\n",
    "spark.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JDBC\n",
    "To enable JDBC connections to the Spark Application, start the HiveThriftServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JDBC Launch option 1\n",
    "```json\n",
    "\"mainClass\": \"org.apache.spark.connect.sql.service.SparkConnectServer\",\n",
    "\"deps\": {\n",
    "    \"packages\": [\"org.apache.spark:spark-connect_2.12:3.5.0\"]\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
