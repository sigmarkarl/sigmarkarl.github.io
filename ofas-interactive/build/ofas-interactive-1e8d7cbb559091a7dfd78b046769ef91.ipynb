{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ofas Interactive Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "A interactive Spark application is a long-running application which the user can interact with on runtime. This can be a notebook application or applications running Spark Connect or HiveThrift servers. Spark Connect supports languages such as Python, Scala and Go and potentially all languages supported by gRPC. The HiveThrift server offers SQL interaction through JDBC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Connect\n",
    "To start a Spark application with SparkConnect server, either run the mainClass SparkConnectServer or enable the SparkConnect plugin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Connect launch option 1\n",
    "```json\n",
    "\"mainClass\": \"org.apache.spark.connect.sql.service.SparkConnectServer\",\n",
    "\"deps\": {\n",
    "    \"packages\": [\"org.apache.spark:spark-connect_2.12:3.5.0\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spark Connect launch option 2\n",
    "```json\n",
    "\"sparkConf\": {\n",
    "    \"spark.plugins\": \"org.apache.spark.sql.connect.SparkConnectPlugin\"\n",
    "},\n",
    "\"deps\": {\n",
    "    \"packages\": [\"org.apache.spark:spark-connect_2.12:3.5.0\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the client side use the ocean-spark-connect (https://pypi.org/project/ocean-spark-connect) python library to interact with the Spark Connect session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ocean_spark_connect.ocean_spark_session import OceanSparkSession\n",
    "\n",
    "spark = OceanSparkSession.Builder().cluster_id(\"osc-cluster\").appid(\"appid\").profile(\"default\").getOrCreate()\n",
    "spark.sql(\"select random()\").show()\n",
    "spark.stop()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JDBC\n",
    "To enable JDBC connections to the Spark Application, start the HiveThriftServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JDBC launch\n",
    "```json\n",
    "\"mainClass\": \"com.netapp.spark.HiveThriftServer\",\n",
    "\"deps\": {\n",
    "    \"packages\": [\"com.netapp.spark:hive:1.2.0\"],\n",
    "    \"repositories\": [\"https://us-central1-maven.pkg.dev/ocean-spark/spark-code-submission-plugin\"]\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
